{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHfoN5XQ/DAhdiX5s76lI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezaKarmali/ML_Helper_Functions/blob/main/Python_Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9he4SbVLRp7"
      },
      "outputs": [],
      "source": [
        "# رسم نمودار خطا در مقابل نرخ یادگیری\n",
        "def Plot_LearningRate_Vs_Loss(Mymodel):\n",
        "  plt.plot(Mymodel.history.history['lr'] ,Mymodel.history.history['loss'])\n",
        "  Min_loss = np.min(Mymodel.history.history['loss'])\n",
        "  LR = [j for i, j in zip(model_14.history.history['loss'], model_14.history.history['lr']) if i == Min_loss]\n",
        "  plt.annotate(f'Min Loss and related lr \\n Loss: {Min_loss} , \\n Lr: {LR[0]}',\n",
        "              xy = (LR[0] ,Min_loss),\n",
        "              fontsize = 10,\n",
        "              xytext = (LR[0]-0.002 ,Min_loss+0.3),\n",
        "              arrowprops = dict(facecolor = 'blue'),\n",
        "              color = 'red')\n",
        "  print(f\"Loss: {tf.round(Min_loss)} , The Best Learning rate: {tf.round(LR[0])}\")\n",
        "  plt.title('Loss vs. Learning Rate')\n",
        "  plt.xlabel(\"Learning rate\")\n",
        "  plt.ylabel(\"Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# رسم تصاویر مربوط به کلاسها در دسته بندی چند کلاسه\n",
        "# names = نام کلاسها در دسته بندی های چند کلاسه\n",
        "def  plot_some_images_of_classes(train_class, class_labels, names ,numberOfImages=4):\n",
        "  import matplotlib.pyplot as plt\n",
        "  import random\n",
        "\n",
        "  if(numberOfImages < 5):\n",
        "     plt.figure(figsize=(numberOfImages*2, numberOfImages*2) , clear=True)\n",
        "  else:\n",
        "     plt.figure(figsize=((numberOfImages//4)*10, (numberOfImages//4)*10) , clear=True)\n",
        "\n",
        "  plt.gca().set_frame_on(False)\n",
        "\n",
        "  for i in range(numberOfImages): #تعداد تصاویر\n",
        "         plt.subplot((numberOfImages//4)+1, 4, i+1)\n",
        "         rand_n =random.randint(1, 60000)\n",
        "         plt.title(f\"{names[class_labels[rand_n]]}({i+1})\")\n",
        "         plt.imshow(train_class[rand_n], cmap=plt.cm.BrBG_r)\n",
        "         plt.xticks([])\n",
        "         plt.yticks([])\n"
      ],
      "metadata": {
        "id": "aFbKipM1LlSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics._plot.confusion_matrix import product\n",
        "# Plot Confusion Matrix\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(12, 12), text_size=9):\n",
        "  # y_true = برچسب های داده های ارزیابی واقعی\n",
        "  # Create the confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize our Confusion Matrix\n",
        "\n",
        "  n_classes = cm.shape[0]\n",
        "\n",
        "  # Let's prettify it\n",
        "  fig, ax=plt.subplots(figsize=figsize)\n",
        "  # Create a matrix plot\n",
        "  plt.xticks(cm[0], class_names, rotation='vertical')\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Set labels to be classes\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arrange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(\n",
        "      title=\"Confusion Matrix\",\n",
        "      xlabel=\"prediction Label\",\n",
        "      ylabel=\"True Label\",\n",
        "      yticks=np.arange(n_classes),\n",
        "      xticks=np.arange(n_classes),\n",
        "      xticklabels=labels,\n",
        "      yticklabels=labels\n",
        "  )\n",
        "\n",
        "  # set x-axis labels to bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Adjust label size\n",
        "  ax.yaxis.label.set_size(text_size)\n",
        "  ax.xaxis.label.set_size(text_size)\n",
        "  ax.title.set_size(text_size)\n",
        "\n",
        "  # Set threshhold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plotthe text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "             size=text_size\n",
        "             )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tLCaktQdPgtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# رسم تصویری تصادفی در تشخیص چند کلاسی\n",
        "def plot_random_image(model, images, true_labels, class_names):\n",
        "  '''\n",
        "    Picks a random image, plots it and it's labels with a prediction and true label.\n",
        "    لازم به یادآوری است در صورتی که مدل روی داده های نرمال سازی شده آموزش دیده باشد\n",
        "    باید تصاویر ورودی هم به فرمت نرمال شده باشند\n",
        "  '''\n",
        "  i = random.randint(0, len(images))\n",
        "\n",
        "  # Create Predictions and targets\n",
        "  target_image = images[i]\n",
        "  pred_probs = model.predict(target_image.reshape(1, 28, 28))\n",
        "  pred_label = class_names[pred_probs.argmax()]\n",
        "  true_label = class_names[true_labels[i]]\n",
        "\n",
        "  # Plot the image\n",
        "  plt.imshow(target_image, cmap=plt.cm.binary)\n",
        "\n",
        "  # Change the color of the titles depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  # Add xlabel information(prediction/true label)\n",
        "  plt.xlabel(\"Pred:{} {:2.0f}%  (True:  {})\".format(\n",
        "      pred_label, 100*tf.reduce_max(pred_probs), true_label,\n",
        "      colors=color)) #Set the color to green or red based on if preiction is rigth or wrong\n",
        "\n",
        "  # Check out a random image as well as its prediction\n",
        "  # plot_random_image(model=model_14,\n",
        "  #                   images=test_data_norm, #always make predictions on the same kind of data your model was traind on\n",
        "  #                   true_labels=test_label,\n",
        "  #                   class_names=class_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "j0pGFecNkitd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# رسم منحنی های هزینه و دقت براساس تابع تاریخ (خروجی مدل تنسور فلو)"
      ],
      "metadata": {
        "id": "xx0n1iikikhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training curves separately\n",
        "def plot_loss_accuracy_curved(history):\n",
        "  \"\"\"\n",
        "  Plot separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs = range(len(history.history[\"loss\"])) # How many epochs did we run for\n",
        "\n",
        "  plt.figure(figsize=(14, 4))\n",
        "  # plot Loss\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, loss, label=\"Loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"Val_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot Accuracy\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, accuracy, label=\"Accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"Val_acuuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "_F0t9QyA2jMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# تابع آماده سازی تصویر برای پیش بینی\n",
        "** ▶ Note: When you train a neural network and you want to make a prediction with it on your own custom data, it's important than your custom data(or new data) is preprocessed into the same format as the data your model was trained on.**"
      ],
      "metadata": {
        "id": "T7x_EDJGblEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import an image and resize and expand it to be able to use it with our model(for prediction)\n",
        "def load_and_prep_image_for_prediction(filename, img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turn it into a tensor and reshapes it\n",
        "  to (img_shape, img_shape, colour_chanels)\n",
        "  \"\"\"\n",
        "  # Read the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode the read file into a tensor\n",
        "  # تنسور فلو توابع زیادی برای دیکد داده های تصویری و جدولی و ... دارد که در اینجا ما از تابه تصویر آن استفاده کرده ایم\n",
        "  img = tf.image.decode_image(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, size=(img_shape, img_shape))\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img"
      ],
      "metadata": {
        "id": "8Ece0UOAbjfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_and_plot(model, file_name=\"\", img_size=224, classNames=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with model\n",
        "  and show the image with the predicted class as the title\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image_for_prediction(filename=file_name, img_shape=img_size)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  if(pred[0] > 1):\n",
        "    pred_class = class_names[pred[0].argmax()]\n",
        "  else:\n",
        "     pred_class = classNames[int(tf.round(pred[0]))]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class} ({pred})%\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "W1myGgntXDv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# رسم تصویر تصادفی"
      ],
      "metadata": {
        "id": "Q0nwbhj9haq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def view_random_image(target_dir, target_class):\n",
        "  # Setup the target directory (we'll view images from here)\n",
        "  target_folder = target_dir + '/' + target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "  print(random_image[0])\n",
        "\n",
        "  # Read in the iamge and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + '/' + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\")\n",
        "  print(f\"Image shape: {img.shape} \") #show the shape of the image\n",
        "  return img\n"
      ],
      "metadata": {
        "id": "PNu7PxG8hk7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorBoard callback Functionize"
      ],
      "metadata": {
        "id": "dAfEYm764l7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating TensorBoard callback (functionalized because we need to create a new one for each model)\n",
        "import datetime\n",
        "\n",
        "def Create_tensorboard_callback(dir_name, expriment_name):\n",
        "  \"\"\"\n",
        "  Exprement_name = Model_Name\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + expreient_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard lof files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "6Il7ZLbS4vCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and testing TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "wWH_rVkRMPN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a create_model() function to create a model from URL\n",
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a Keras Sequentioal model with it.\n",
        "\n",
        "  Args:\n",
        "     model_url (str): A tensorFlow Hub feature extraction URL.\n",
        "     num_classes (str): Number of output neurons in the ouput layer,\n",
        "        should be equal to number of target classes, default 10.\n",
        "  Returns:\n",
        "     An uncompiled Keras Sequential model with model_urlas feature extractor\n",
        "     layer and Dense output layer with num_classes output neurons.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False, # freeze the already learned patterns\n",
        "                                           name=\"feature_extraction_layer\",\n",
        "                                           input_shape=IMAGE_SHAPE + (3,))\n",
        "\n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_classes, activation=\"softmax\", name='output_layer')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "EsxRz7JmMhDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHM0vKbcOoce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}